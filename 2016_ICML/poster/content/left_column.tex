
%place your content here, feel free to create subcontent files

\begin{block}{\blocktitle{Abstract}}
\justifying
We propose minimum regret search (MRS), a novel acquisition function for Bayesian
optimization. MRS bears similarities with information-theoretic approaches
such as entropy search (ES). However, while ES aims in each query at maximizing the
information gain with respect to the global maximum, MRS aims at minimizing the
expected simple regret of its ultimate recommendation for the optimum. While empirically ES and MRS perform similar in most of the
cases, MRS produces fewer outliers with high simple regret than ES. We provide empirical
results both for a synthetic single-task optimization problem as well as for a
simulated multi-task robotic control problem.
\end{block}

\begin{block}{\blocktitle{Background}}
\textbf{Bayesian optimization} \cite{shahriari_taking_2016}:
\begin{itemize}
\item aims at black-box optimization problems $\mathbf{x} = \arg\min_{\mathbf{x} \in \mathcal{X}} f(x)$ of some function $f: \mathcal{X} \to \mathbb{R}$ on some bounded set $\mathcal{X} \subset \mathbb{R}^D$.
\item maintains a \emph{probabilistic model} for $f(\mathbf{x})$, typically a Gaussian process (GP)
\item decides on a query point $\mathbf{x}_{n+1}$ where $f$ will be evaluated next based on GP posterior of first $n$ observations $\mathcal{D}_n=\{(\mathbf{x}_i, y_i)\}_{i=1}^n$ and an \emph{acquisition function}
\end{itemize}

Acquisition functions decide where to query next:
\begin{itemize}
\item Upper-Confidence Bound (UCB): $a_{UCB}(\mathbf{x};
\mathcal{D}_n) = \mu_{n}(\mathbf{x}) + \kappa_n \sigma_{n}(\mathbf{x})$
\end{itemize}

\end{block}

\begin{block}{\blocktitle{Minimum Regret Search}}
\emph{Idea:} 

Entropy Search (ES):
\begin{itemize}
 \item estimate probability $p_{opt}(\theta)$ that the global optimum of unknown function $f$ is at $\theta$ at finitely many points $\{\theta^c\}_{i=1}^{N_\theta}$ and approximate using Monte Carlo integration
 \item predict the change of GP when drawing a sample at the query point
$\theta^q$ and assuming $N_y$ different outcomes $\{y^{(i)}\}$ sampled from the
GP's predictive distribution at $\theta^q$
 \item select query point that minimizes the average loss (maximizes the relative entropy) $\mathcal{L}(p_{opt}[\theta^q]) = - \int p_{opt}[\theta^q](\theta) \log \frac{p_{opt}[\theta^q](\theta)}{U_I(\theta)}, \text{d}\theta$,  where $p_{opt}[\theta^q]$ denotes the probability
 distribution of the global optimum \emph{after} an assumed query at $\theta^q$.
\end{itemize}

Minimum Regret Search (MRS):
\begin{itemize}
 \item 
\end{itemize}
\end{block}

\begin{block}{\blocktitle{Illustration}}
\vspace*{1cm}

\begin{figure}
\centering
\includegraphics[width=0.48\columnwidth]{../pics/regret_illustration}
\includegraphics[width=0.48\columnwidth]{../pics/acq_comparison}
\caption{(Left) Illustration of GP posterior, probability of maximum $p^\star$, expected regret ER, and  $\mathbb{E}[\max(f(\mathbf{x}) - f(1.5), 0)]$ (scale on the right-hand side). (Right) Illustration of GP posterior and different acquisition function. Absolute values have been normalized such that the mean value of an acquisition function is $0.5$. Best seen in color.}
\label{fig:MRS_illustration}
\end{figure}
\end{block}

\begin{block}{\blocktitle{Synthetic Single-Task Benchmark}}
\begin{itemize}
 \item Comparison of different approaches for exploration
 \begin{enumerate}
  \item Active contextual entropy search ($N_{nn} = 20$ and $N_{nn} = 1$)
  \item BO-CPS + Entropy Search +  random context selection
  \item BO-CPS + GP-UCB with $\kappa=5.0$ (``pure exploration'') + random context selection
  \item Random parameter and context selection
 \end{enumerate}
 \item Entropy Search outperforms GP-UCB because UCB aggressively samples parameters at the boundaries (high uncertainty but low global information)
 \item ACES outperforms random context selection, in particular when $N_{nn} = 20$
 \item ACES\_20 tends to avoid performing trials at the boundaries of the context space
\end{itemize}

\end{block}